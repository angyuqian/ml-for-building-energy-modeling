{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from utils.constants import get_tmass_idx\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client(\"s3\")\n",
    "bucket = \"ml-for-bem\"\n",
    "experiment_name = \"validation/v2\"\n",
    "local_dir = Path(\"data\") / \"temp\" / \"validation\" / \"v2\"\n",
    "\n",
    "\n",
    "def open_and_load_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004999637603759766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d6e541b8c54f5db916401e2c62e5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing features...\n",
      "Uploading to S3...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get the template file keys\n",
    "\"\"\"\n",
    "with open(local_dir / \"template\" / os.listdir(local_dir / \"template\")[0], \"r\") as f:\n",
    "    template = json.load(f)\n",
    "    template_keys = list(template.keys())\n",
    "    template_keys = [k for k in template_keys if k not in [\"core_depth\"]]\n",
    "\n",
    "\"\"\"\n",
    "Get a list of all the feature files and open them\n",
    "\"\"\"\n",
    "feature_files = list((Path(local_dir) / \"features\").glob(\"*.json\"))\n",
    "template_files = list((Path(local_dir) / \"template\").glob(\"*.json\"))\n",
    "idf_files = list((Path(local_dir) / \"idf\").glob(\"*.idf\"))\n",
    "\n",
    "features = []\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    res = list(\n",
    "        tqdm(executor.map(open_and_load_json, feature_files), total=len(feature_files))\n",
    "    )\n",
    "    for r in res:\n",
    "        features.extend(r)\n",
    "\n",
    "\"\"\"\n",
    "Conver the features to a dataframe and do some light post-processing\n",
    "\"\"\"\n",
    "print(\"Post-processing features...\")\n",
    "features = pd.DataFrame(features)\n",
    "features = features.set_index(keys=[\"building_id\", \"name\"]).sort_index()\n",
    "\n",
    "# set facade mass\n",
    "features[\"FacadeMass\"] = features[\"FacadeMass\"].apply(get_tmass_idx)\n",
    "features[\"FacadeMass\"] = features[\"RoofMass\"].apply(get_tmass_idx)\n",
    "\n",
    "# set roof/ground adiabatic\n",
    "roof_mask = features.floor == features.n_floors - 1\n",
    "ground_mask = features.floor == 0\n",
    "features[\"roof_2_footprint\"] = 0\n",
    "features.loc[roof_mask, \"roof_2_footprint\"] = 1\n",
    "features[\"ground_2_footprint\"] = 0\n",
    "features.loc[ground_mask, \"ground_2_footprint\"] = 1\n",
    "\n",
    "# drop core depth\n",
    "if \"core_depth\" in features.columns:\n",
    "    features = features.drop(columns=[\"core_depth\"])\n",
    "features = features.rename(columns={\"total_perimiter_length\": \"total_perimeter_length\"})\n",
    "\n",
    "# add some additional features\n",
    "zone_facade_area = features.zone_edge_length * features.height\n",
    "zone_perim_floor_area_to_facade_area = features.zone_perimeter_area / zone_facade_area\n",
    "zone_core_area_to_perimeter_area = features.core_area / features.zone_perimeter_area\n",
    "building_perimeter_area = features.footprint_area - features.core_area\n",
    "building_core_area_to_perimeter_area = features.core_area / building_perimeter_area\n",
    "building_facade_area = features.total_perimeter_length * features.height\n",
    "features[\"building_perimeter_area_per_one_floor\"] = building_perimeter_area\n",
    "features[\"building_core_area_to_perimeter_area\"] = building_core_area_to_perimeter_area\n",
    "features[\"building_facade_area_per_one_floor\"] = building_facade_area\n",
    "features[\"zone_facade_area\"] = zone_facade_area\n",
    "features[\"zone_perim_floor_area_to_facade_area\"] = zone_perim_floor_area_to_facade_area\n",
    "features[\"zone_core_area_to_perimeter_area\"] = zone_core_area_to_perimeter_area\n",
    "\n",
    "# sort columns\n",
    "features = features[sorted(list(features.columns))]\n",
    "shading_cols = [col for col in features.columns if \"shading_\" in col]\n",
    "shading_cols = [f\"shading_{i}\" for i in range(len(shading_cols))]\n",
    "\n",
    "features = features[\n",
    "    [col for col in features.columns if col not in shading_cols] + shading_cols\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "Aggregate building level features which don't vary\n",
    "\"\"\"\n",
    "building_features = features.groupby(level=\"building_id\").first()[\n",
    "    [\"total_perimeter_length\", \"gfa\", \"footprint_area\", \"n_floors\", \"core_area\"]\n",
    "    + template_keys\n",
    "    + [col for col in features.columns if \"building\" in col]\n",
    "]\n",
    "\n",
    "assert (features[\"weight\"].sum() - len(features)) < 1e-6\n",
    "assert (features.groupby(\"building_id\")[\"weight\"].sum() - 1).abs().max() < 1e-6\n",
    "\n",
    "\"\"\"\n",
    "Save to HDF\n",
    "\"\"\"\n",
    "features.to_hdf(local_dir / \"features.hdf\", key=\"shoeboxes\")\n",
    "building_features.to_hdf(local_dir / \"features.hdf\", key=\"buildings\")\n",
    "\n",
    "\"\"\"\n",
    "Upload to S3\n",
    "\"\"\"\n",
    "print(\"Uploading to S3...\")\n",
    "client.upload_file(\n",
    "    Filename=str(local_dir / \"features.hdf\"),\n",
    "    Bucket=bucket,\n",
    "    Key=f\"{experiment_name}/features.hdf\",\n",
    ")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading feature json files...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003174304962158203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade6999e83ac4373993a970b5d3213a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading template json files...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002999544143676758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e47833cc73f44b9aa4312fcfb5ab5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading idf files...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003992557525634766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6647ffea367d4097aa66f5065494ea94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def upload_file_to_s3(path):\n",
    "    client.upload_file(\n",
    "        Filename=str(path),\n",
    "        Bucket=bucket,\n",
    "        Key=f\"{experiment_name}/{path.parent.name}/{path.name}\",\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Uploading feature json files...\")\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    list(tqdm(executor.map(upload_file_to_s3, feature_files), total=len(feature_files)))\n",
    "\n",
    "print(\"Uploading template json files...\")\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    list(\n",
    "        tqdm(executor.map(upload_file_to_s3, template_files), total=len(template_files))\n",
    "    )\n",
    "\n",
    "print(\"Uploading idf files...\")\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    list(tqdm(executor.map(upload_file_to_s3, idf_files), total=len(template_files)))\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-for-bem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
