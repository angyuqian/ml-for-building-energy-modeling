{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema Usage\n",
    "\n",
    "The schema does not actually store any data.  Instead, it is an interface which allows us to interact with numpy/torch tensors in a semantic manner.  It lets us convert between storage vectors (i.e. how we store the building parameters numerically on disk), simulation objects (e.g. Archetypal Templates and PyUmi Shoeboxes) and machine learning model imports (i.e. torch tensors with full hourly schedule data)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup\n",
    "\n",
    "We need some jank to get relative imports working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from nrel_uitls import CLIMATEZONES, RESTYPES\n",
    "import json\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anacondas\\envs\\ml-for-bem-sampling\\lib\\site-packages\\outdated\\utils.py:14: OutdatedPackageWarning: The package energy-pandas is out of date. Your version is 0.3.2, the latest is 0.3.3.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "from schema import Schema, ShoeboxGeometryParameter, BuildingTemplateParameter, WhiteboxSimulation, WindowParameter\n",
    "schema = Schema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what's in the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batch_id',\n",
       " 'variation_id',\n",
       " 'program_type',\n",
       " 'vintage',\n",
       " 'climate_zone',\n",
       " 'base_epw',\n",
       " 'width',\n",
       " 'height',\n",
       " 'facade_2_footprint',\n",
       " 'perim_2_footprint',\n",
       " 'roof_2_footprint',\n",
       " 'footprint_2_ground',\n",
       " 'shading_fact',\n",
       " 'wwr',\n",
       " 'orientation',\n",
       " 'HeatingSetpoint',\n",
       " 'CoolingSetpoint',\n",
       " 'HeatingCoeffOfPerf',\n",
       " 'CoolingCoeffOfPerf',\n",
       " 'FlowRatePerFloorArea',\n",
       " 'LightingPowerDensity',\n",
       " 'EquipmentPowerDensity',\n",
       " 'PeopleDensity',\n",
       " 'Infiltration',\n",
       " 'FacadeMass',\n",
       " 'RoofMass',\n",
       " 'FacadeRValue',\n",
       " 'RoofRValue',\n",
       " 'SlabRValue',\n",
       " 'WindowSettings',\n",
       " 'schedules_seed',\n",
       " 'schedules']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema.parameter_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access a schema parameter from the schema with list indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---width---\n",
      "shape_storage=(1,), shape_ml=(1,), dtype=scalar\n",
      "Width [m]\n",
      "---schedules---\n",
      "shape_storage=(3, 19), shape_ml=(3, 8760), dtype=matrix\n",
      "A matrix in the storage vector with operations to apply to schedules; a matrix of timeseries in ml vector\n",
      "---orientation---\n",
      "shape_storage=(1,), shape_ml=(4,), dtype=onehot\n",
      "Shoebox Orientation\n"
     ]
    }
   ],
   "source": [
    "print(schema[\"width\"])\n",
    "print(schema[\"schedules\"])\n",
    "print(schema[\"orientation\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that each parameter may have multiple different lengths in the storage vector and ML vector.\n",
    "\n",
    "We can also print a summary of the whole schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Schema --------\n",
      "---- batch_id ----\n",
      "shape storage: (1,) / shape ml: (0,)\n",
      "location storage: 0->1 / location ml: 0->0\n",
      "\n",
      "---- variation_id ----\n",
      "shape storage: (1,) / shape ml: (0,)\n",
      "location storage: 1->2 / location ml: 0->0\n",
      "\n",
      "---- program_type ----\n",
      "shape storage: (1,) / shape ml: (19,)\n",
      "location storage: 2->3 / location ml: 0->19\n",
      "\n",
      "---- vintage ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 3->4 / location ml: 19->20\n",
      "\n",
      "---- climate_zone ----\n",
      "shape storage: (1,) / shape ml: (15,)\n",
      "location storage: 4->5 / location ml: 20->35\n",
      "\n",
      "---- base_epw ----\n",
      "shape storage: (1,) / shape ml: (0,)\n",
      "location storage: 5->6 / location ml: 35->35\n",
      "\n",
      "---- width ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 6->7 / location ml: 35->36\n",
      "\n",
      "---- height ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 7->8 / location ml: 36->37\n",
      "\n",
      "---- facade_2_footprint ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 8->9 / location ml: 37->38\n",
      "\n",
      "---- perim_2_footprint ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 9->10 / location ml: 38->39\n",
      "\n",
      "---- roof_2_footprint ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 10->11 / location ml: 39->40\n",
      "\n",
      "---- footprint_2_ground ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 11->12 / location ml: 40->41\n",
      "\n",
      "---- shading_fact ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 12->13 / location ml: 41->42\n",
      "\n",
      "---- wwr ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 13->14 / location ml: 42->43\n",
      "\n",
      "---- orientation ----\n",
      "shape storage: (1,) / shape ml: (4,)\n",
      "location storage: 14->15 / location ml: 43->47\n",
      "\n",
      "---- HeatingSetpoint ----\n",
      "shape storage: (1,) / shape ml: (0,)\n",
      "location storage: 15->16 / location ml: 47->47\n",
      "\n",
      "---- CoolingSetpoint ----\n",
      "shape storage: (1,) / shape ml: (0,)\n",
      "location storage: 16->17 / location ml: 47->47\n",
      "\n",
      "---- HeatingCoeffOfPerf ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 17->18 / location ml: 47->48\n",
      "\n",
      "---- CoolingCoeffOfPerf ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 18->19 / location ml: 48->49\n",
      "\n",
      "---- FlowRatePerFloorArea ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 19->20 / location ml: 49->50\n",
      "\n",
      "---- LightingPowerDensity ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 20->21 / location ml: 50->51\n",
      "\n",
      "---- EquipmentPowerDensity ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 21->22 / location ml: 51->52\n",
      "\n",
      "---- PeopleDensity ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 22->23 / location ml: 52->53\n",
      "\n",
      "---- Infiltration ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 23->24 / location ml: 53->54\n",
      "\n",
      "---- FacadeMass ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 24->25 / location ml: 54->55\n",
      "\n",
      "---- RoofMass ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 25->26 / location ml: 55->56\n",
      "\n",
      "---- FacadeRValue ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 26->27 / location ml: 56->57\n",
      "\n",
      "---- RoofRValue ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 27->28 / location ml: 57->58\n",
      "\n",
      "---- SlabRValue ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 28->29 / location ml: 58->59\n",
      "\n",
      "---- WindowSettings ----\n",
      "shape storage: (3,) / shape ml: (3,)\n",
      "location storage: 29->32 / location ml: 59->62\n",
      "\n",
      "---- schedules_seed ----\n",
      "shape storage: (1,) / shape ml: (0,)\n",
      "location storage: 32->33 / location ml: 62->62\n",
      "\n",
      "---- schedules ----\n",
      "shape storage: (3, 19) / shape ml: (3, 8760)\n",
      "location storage: 33->90 / location ml: 62->26342\n",
      "\n",
      "Total length of storage vectors: 90 / Total length of ml vectors: 26342\n"
     ]
    }
   ],
   "source": [
    "print(schema)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the length of the storage vector is significantly smaller than the length the vector the ML model will see."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating new design vectors in storage space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's generate a new, empty design vector, and update the Roof R-Value, and then check that it updated correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_vector = schema.generate_empty_storage_vector()\n",
    "schema.update_storage_vector(storage_vector=storage_vector, parameter=\"RoofRValue\", value=2.5)\n",
    "schema[\"RoofRValue\"].extract_storage_values(storage_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print out the full vector, we should be able to see the 2.5 and a whole bunch of zeros (and a few 1s in the schedules indicated to use the original schedules):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  2.5 0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n"
     ]
    }
   ],
   "source": [
    "print(storage_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new batch of designs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 90)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 20\n",
    "storage_batch = schema.generate_empty_storage_batch(batch_size)\n",
    "storage_batch.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we see that it has 20 design vectors with 90 values each.\n",
    "\n",
    "Let's try updating all of the facade R-values values in a batch with the same value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2],\n",
       "       [1.2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema.update_storage_batch(storage_batch, parameter=\"FacadeRValue\", value=1.2)\n",
    "schema[\"FacadeRValue\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try updating an entire batch with random values.  We can also unnormalize the uniform random variable into the desired range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.28556669],\n",
       "       [2.21188443],\n",
       "       [2.19737834],\n",
       "       [4.89606833],\n",
       "       [0.80564111],\n",
       "       [2.21539627],\n",
       "       [2.78249956],\n",
       "       [0.57101388],\n",
       "       [3.86063212],\n",
       "       [0.86783286],\n",
       "       [3.97274649],\n",
       "       [0.64313714],\n",
       "       [2.30029162],\n",
       "       [1.39938382],\n",
       "       [4.00864892],\n",
       "       [2.65655458],\n",
       "       [1.62824317],\n",
       "       [2.64778385],\n",
       "       [0.14563769],\n",
       "       [2.43202887]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter = \"SlabRValue\"\n",
    "n = batch_size\n",
    "shape = (n, *schema[parameter].shape_storage)\n",
    "values = np.random.rand(*shape) # create a random sample with appropriate shape\n",
    "values = schema[parameter].unnormalize(values) # schema parameter must be a numeric type with min/max defined for unnormalize to work\n",
    "schema.update_storage_batch(storage_batch, parameter=parameter, value=values)\n",
    "schema[parameter].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try updating just a subset of the batch by using the `index` parameter:\n",
    "\n",
    "*nb: we can also use an int instead of a tuple for `index` to only update a single vector's parameter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2       ],\n",
       "       [1.2       ],\n",
       "       [0.63747384],\n",
       "       [0.79469011],\n",
       "       [0.74784675],\n",
       "       [0.51698986],\n",
       "       [0.97283952],\n",
       "       [0.35172437],\n",
       "       [0.60888897],\n",
       "       [0.58808171],\n",
       "       [1.2       ],\n",
       "       [1.2       ],\n",
       "       [1.2       ],\n",
       "       [1.2       ],\n",
       "       [1.2       ],\n",
       "       [1.2       ],\n",
       "       [1.2       ],\n",
       "       [1.2       ],\n",
       "       [1.2       ],\n",
       "       [1.2       ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 2\n",
    "n = 8\n",
    "end = start + n\n",
    "parameter = \"FacadeRValue\"\n",
    "shape = (n, *schema[parameter].shape_storage)\n",
    "values = np.random.rand(*shape) # create a random sample with appropriate shape\n",
    "\n",
    "schema.update_storage_batch(storage_batch, index=(start,end), parameter=parameter, value=values)\n",
    "schema[parameter].extract_storage_values_batch(storage_batch) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful technique will be to start with a small batch, and then duplicate it in concatenations along `axis=0` as we build up our mixed grid/hypercube/random samples.  Let's start by creating a new batch with a single vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 90)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_batch = schema.generate_empty_storage_batch(1)\n",
    "storage_batch.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say some baseline parameters (e.g. pulled from ResStock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00e+00, 0.00e+00, 3.00e+00, 1.92e+03, 1.20e+01, 2.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 7.20e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 2.30e+00, 3.10e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [0.00e+00, 0.00e+00, 3.00e+00, 1.92e+03, 1.20e+01, 2.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 7.20e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 2.30e+00, 3.10e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [0.00e+00, 0.00e+00, 3.00e+00, 1.92e+03, 1.20e+01, 2.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 7.20e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 2.30e+00, 3.10e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n",
       "       [0.00e+00, 0.00e+00, 3.00e+00, 1.92e+03, 1.20e+01, 2.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 7.20e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 2.30e+00, 3.10e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./data/city_map.json\",\"r\") as f:\n",
    "\tcity_map = json.load(f)\n",
    "\n",
    "schema.update_storage_batch(storage_batch, parameter=\"FacadeRValue\", value=2.3)\n",
    "schema.update_storage_batch(storage_batch, parameter=\"RoofRValue\", value=3.1)\n",
    "schema.update_storage_batch(storage_batch, parameter=\"LightingPowerDensity\", value=7.2)\n",
    "schema.update_storage_batch(storage_batch, parameter=\"program_type\", value=RESTYPES[\"Multi-Family with 5+ Units\"])\n",
    "schema.update_storage_batch(storage_batch, parameter=\"vintage\", value=1920)\n",
    "schema.update_storage_batch(storage_batch, parameter=\"climate_zone\", value=CLIMATEZONES[\"5A\"])\n",
    "schema.update_storage_batch(storage_batch, parameter=\"base_epw\", value=city_map[\"FL, Lehigh Acres\"][\"idx\"])\n",
    "storage_batch = np.concatenate([storage_batch for _ in range(4)], axis=0)\n",
    "storage_batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set the orientations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = np.arange(4).reshape(-1,1)\n",
    "parameter = \"orientation\"\n",
    "schema.update_storage_batch(storage_batch, parameter=parameter, value=values)\n",
    "schema[parameter].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!  Now let's stack this up and begin generating some geometric variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientations_per_base = 4\n",
    "geometric_variations_per_orientation = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 90)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_batch = np.repeat(storage_batch, geometric_variations_per_orientation, axis=0)\n",
    "storage_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema[\"orientation\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!  let's start populating this: if we wanted to use repeating values, we could do nested loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = geometric_variations_per_orientation # how many design vectors in this mini batch\n",
    "for i in range(orientations_per_base):\n",
    "\tstart = i*n # where this mini batch starts in the parent batch\n",
    "\tend = start + n # where this mini batch ends in the parent batch\n",
    "\tfor j,parameter in enumerate(schema.parameters):\n",
    "\t\tif isinstance(parameter, ShoeboxGeometryParameter):\n",
    "\t\t\tname = parameter.name\n",
    "\t\t\tmean = parameter.mean\n",
    "\t\t\tstd = parameter.std\n",
    "\t\t\tshape = parameter.shape_storage\n",
    "\t\t\tnp.random.seed(j+20923) # arbitrary but reliable seed\n",
    "\t\t\tvalues = np.random.normal(loc=mean, scale=std, size=(n, *shape))\n",
    "\t\t\t# values = parameter.unnormalize(values)\n",
    "\t\t\tschema.update_storage_batch(storage_batch, index=(start,end), parameter=name, value=values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34444465],\n",
       "       [0.05      ],\n",
       "       [0.33708715],\n",
       "       [0.16022385],\n",
       "       [0.56547156],\n",
       "       [0.34444465],\n",
       "       [0.05      ],\n",
       "       [0.33708715],\n",
       "       [0.16022385],\n",
       "       [0.56547156],\n",
       "       [0.34444465],\n",
       "       [0.05      ],\n",
       "       [0.33708715],\n",
       "       [0.16022385],\n",
       "       [0.56547156],\n",
       "       [0.34444465],\n",
       "       [0.05      ],\n",
       "       [0.33708715],\n",
       "       [0.16022385],\n",
       "       [0.56547156]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema[\"wwr\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.53980835],\n",
       "       [7.08775209],\n",
       "       [5.68124462],\n",
       "       [5.36848356],\n",
       "       [4.65878866],\n",
       "       [4.53980835],\n",
       "       [7.08775209],\n",
       "       [5.68124462],\n",
       "       [5.36848356],\n",
       "       [4.65878866],\n",
       "       [4.53980835],\n",
       "       [7.08775209],\n",
       "       [5.68124462],\n",
       "       [5.36848356],\n",
       "       [4.65878866],\n",
       "       [4.53980835],\n",
       "       [7.08775209],\n",
       "       [5.68124462],\n",
       "       [5.36848356],\n",
       "       [4.65878866]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema[\"width\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, these are repeating correctly!  Now, suppose we want to just slightly perturb all of these so that they aren't perfectly repeating, but are close to repeating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.50783096],\n",
       "       [7.10805712],\n",
       "       [5.70969198],\n",
       "       [5.27921971],\n",
       "       [4.61290778],\n",
       "       [4.44565827],\n",
       "       [7.10161841],\n",
       "       [5.69719431],\n",
       "       [5.2850572 ],\n",
       "       [4.58177482],\n",
       "       [4.47766668],\n",
       "       [7.1182584 ],\n",
       "       [5.75855261],\n",
       "       [5.42826064],\n",
       "       [4.59308603],\n",
       "       [4.57370062],\n",
       "       [7.10369615],\n",
       "       [5.5915765 ],\n",
       "       [5.33658159],\n",
       "       [4.63718082]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = storage_batch.shape[0]\n",
    "for i,parameter in enumerate(schema.parameters):\n",
    "\tif isinstance(parameter, ShoeboxGeometryParameter):\n",
    "\t\tname = parameter.name\n",
    "\t\tshape = parameter.shape_storage\n",
    "\t\tperturbations = np.random.rand(n,*shape)*0.2 - 0.1\n",
    "\t\tvalues = parameter.extract_storage_values_batch(storage_batch)\n",
    "\t\tvalues += perturbations\n",
    "\t\tschema.update_storage_batch(storage_batch,parameter=name,value=values)\n",
    "\n",
    "schema[\"width\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  We see that they are close to their previous values, but not identical.  \n",
    "\n",
    "Alternatively, we might prefer to simply use fully random geometric variations for all of our orientation duplicates, rather than repeating the geometry across orientations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4432166 ],\n",
       "       [0.33710959],\n",
       "       [0.4739605 ],\n",
       "       [0.82761665],\n",
       "       [0.81276337],\n",
       "       [0.40249355],\n",
       "       [0.22704208],\n",
       "       [0.49019141],\n",
       "       [0.06389378],\n",
       "       [0.64614621],\n",
       "       [0.75214811],\n",
       "       [0.39788008],\n",
       "       [0.25404495],\n",
       "       [0.56076387],\n",
       "       [0.15108382],\n",
       "       [0.256085  ],\n",
       "       [0.34024429],\n",
       "       [0.42906409],\n",
       "       [0.47522886],\n",
       "       [0.61353465]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = storage_batch.shape[0]\n",
    "for i,parameter in enumerate(schema.parameters):\n",
    "\tif isinstance(parameter, ShoeboxGeometryParameter):\n",
    "\t\tname = parameter.name\n",
    "\t\tshape = parameter.shape_storage\n",
    "\t\tvalues = np.random.rand(n,*shape)\n",
    "\t\tvalues = parameter.unnormalize(values)\n",
    "\t\tschema.update_storage_batch(storage_batch,parameter=name,value=values)\n",
    "\n",
    "schema[\"width\"].extract_storage_values_batch(storage_batch)\n",
    "schema[\"wwr\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, if a normal distribution is desired, we can do that as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21695047],\n",
       "       [0.6391094 ],\n",
       "       [0.29529725],\n",
       "       [0.05      ],\n",
       "       [0.32881206],\n",
       "       [0.43934897],\n",
       "       [0.28292817],\n",
       "       [0.05      ],\n",
       "       [0.82733875],\n",
       "       [0.15145752],\n",
       "       [0.27136917],\n",
       "       [0.09045884],\n",
       "       [0.26192168],\n",
       "       [0.24751366],\n",
       "       [0.39748335],\n",
       "       [0.28785416],\n",
       "       [0.49790465],\n",
       "       [0.52373069],\n",
       "       [0.35036656],\n",
       "       [0.14348296]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = storage_batch.shape[0]\n",
    "for i,parameter in enumerate(schema.parameters):\n",
    "    if isinstance(parameter, ShoeboxGeometryParameter):\n",
    "        name = parameter.name\n",
    "        mean = parameter.mean\n",
    "        std = parameter.std\n",
    "        shape = parameter.shape_storage\n",
    "        values = np.random.normal(loc=mean, scale=std, size=(n,*shape))\n",
    "        schema.update_storage_batch(storage_batch,parameter=name,value=values)\n",
    "\n",
    "schema[\"width\"].extract_storage_values_batch(storage_batch)\n",
    "schema[\"wwr\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on in this file, we will be inspecting template parameters as well, so let's just arbitrarily set some building template parameters for each design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPD:\n",
      "[[5.73466772]\n",
      " [7.68669191]\n",
      " [9.37173696]]\n",
      "Window Settings:\n",
      "[[3.14958077 0.60625715 0.41883353]\n",
      " [6.04476975 0.48973266 0.66778925]\n",
      " [6.17792006 0.45298213 0.49137614]]\n"
     ]
    }
   ],
   "source": [
    "n = storage_batch.shape[0]\n",
    "for i,parameter in enumerate(schema.parameters):\n",
    "\tif isinstance(parameter, (BuildingTemplateParameter, WindowParameter)):\n",
    "\t\tname = parameter.name\n",
    "\t\tmean = parameter.mean\n",
    "\t\tstd = parameter.std\n",
    "\t\tshape = parameter.shape_storage\n",
    "\t\tvalues = np.random.normal(loc=mean, scale=std, size=(n,*shape))\n",
    "\t\tschema.update_storage_batch(storage_batch,parameter=name,value=values)\n",
    "\n",
    "print(\"LPD:\")\n",
    "print(schema[\"LightingPowerDensity\"].extract_storage_values_batch(storage_batch)[:3])\n",
    "print(\"Window Settings:\")\n",
    "print(schema[\"WindowSettings\"].extract_storage_values_batch(storage_batch)[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose this was our finished batch.  We can save it to an HDF5 file.  Let's say this was building 23 from our ResStock database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from storage import upload_to_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Storage:Uploading ./data/hdf5/batch_00023.hdf5 to bucket:demo-batch-data/batch_00023.hdf5...\n",
      "INFO:Storage:Done uploading.\n"
     ]
    }
   ],
   "source": [
    "# Update the building IDs\n",
    "batch_id = 23 # suppose this is the base building we are drawing from\n",
    "n = storage_batch.shape[0]\n",
    "variation_ids = np.arange(n)\n",
    "schema.update_storage_batch(storage_batch,parameter=\"batch_id\",value=batch_id)\n",
    "schema.update_storage_batch(storage_batch,parameter=\"variation_id\",value=variation_ids)\n",
    "\n",
    "# Write to an HDF5 file\n",
    "slug = f\"batch_{batch_id:05d}.hdf5\"\n",
    "outfile = f\"./data/hdf5/{slug}\"\n",
    "with h5py.File(outfile,\"w\") as f:\n",
    "    f.create_dataset(name=\"storage_vectors\", shape=storage_batch.shape, dtype=storage_batch.dtype, data=storage_batch)\n",
    "\n",
    "# upload to cloud bucket for easy backup\n",
    "destination = f\"demo-batch-data/{slug}\"\n",
    "upload_to_bucket(destination, outfile)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's suppose you want to simulate a design vector.  Let's open up an HDF5 file and read in only the first storage vector to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.0, 0.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_id = 23\n",
    "slug = f\"batch_{batch_id:05d}.hdf5\"\n",
    "outfile = f\"./data/hdf5/{slug}\"\n",
    "storage_vector = None\n",
    "with h5py.File(outfile,'r') as f:\n",
    "    storage_vector = f[\"storage_vectors\"][0]\n",
    "\n",
    "schema[\"batch_id\"].extract_storage_values(storage_vector), schema[\"variation_id\"].extract_storage_values(storage_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Looks like we successfully opened the 0th design variation from batch 23.\n",
    "\n",
    "Now let's create a simulation object for this storage vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# just using \n",
    "# TODO: orientation\n",
    "# TODO: setpoint value overlaps\n",
    "schema.update_storage_vector(storage_vector, parameter=\"climate_zone\", value=CLIMATEZONES[\"5A\"])\n",
    "schema.update_storage_vector(storage_vector, parameter=\"vintage\", value=1920)\n",
    "schema.update_storage_vector(storage_vector, parameter=\"program_type\", value=RESTYPES[\"Multi-Family with 5+ Units\"])\n",
    "schema.update_storage_vector(storage_vector, parameter=\"base_epw\", value=city_map[\"FL, Lehigh Acres\"][\"idx\"])\n",
    "schema.update_storage_vector(storage_vector, \"height\", 3)\n",
    "schema.update_storage_vector(storage_vector, \"width\", 3)\n",
    "schema.update_storage_vector(storage_vector, \"facade_2_footprint\", 0.3)\n",
    "schema.update_storage_vector(storage_vector, \"perim_2_footprint\", 0.5)\n",
    "schema.update_storage_vector(storage_vector, \"roof_2_footprint\", 0.5)\n",
    "schema.update_storage_vector(storage_vector, \"footprint_2_ground\", 0.5)\n",
    "schema.update_storage_vector(storage_vector, \"wwr\", 0.4)\n",
    "schema.update_storage_vector(storage_vector, \"Infiltration\", 0.3)\n",
    "schema.update_storage_vector(storage_vector, \"HeatingSetpoint\", 17)\n",
    "schema.update_storage_vector(storage_vector, \"CoolingSetpoint\", 23)\n",
    "schema.update_storage_vector(storage_vector, \"PeopleDensity\", 0.05)\n",
    "schema.update_storage_vector(storage_vector, \"LightingPowerDensity\", 18)\n",
    "schema.update_storage_vector(storage_vector, \"EquipmentPowerDensity\", 7)\n",
    "schema.update_storage_vector(storage_vector, \"RoofRValue\", 3)\n",
    "schema.update_storage_vector(storage_vector, \"SlabRValue\", 0.9)\n",
    "schema.update_storage_vector(storage_vector, \"FacadeRValue\", 2.)\n",
    "schema.update_storage_vector(storage_vector, \"FacadeMass\", 120000)\n",
    "schema.update_storage_vector(storage_vector, \"RoofMass\", 120000)\n",
    "whitebox_sim = WhiteboxSimulation(schema, storage_vector)\n",
    "whitebox_sim.shoebox.view_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at the semantic objects that have been configured!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EPD:\", whitebox_sim.template.Perimeter.Loads.EquipmentPowerDensity)\n",
    "print(\"LPD:\", whitebox_sim.template.Perimeter.Loads.LightingPowerDensity)\n",
    "print(\"PPD:\", whitebox_sim.template.Core.Loads.PeopleDensity)\n",
    "print(\"Inf:\", whitebox_sim.template.Core.Ventilation.Infiltration)\n",
    "print(\"RRf:\", whitebox_sim.template.Perimeter.Constructions.Roof.r_value)\n",
    "print(\"RPr:\", whitebox_sim.template.Perimeter.Constructions.Partition.r_value)\n",
    "print(\"RSl:\", whitebox_sim.template.Perimeter.Constructions.Slab.r_value)\n",
    "print(\"RGn:\", whitebox_sim.template.Perimeter.Constructions.Ground.r_value)\n",
    "print(\"RFc:\", whitebox_sim.template.Perimeter.Constructions.Facade.r_value)\n",
    "print(\"EPW:\", whitebox_sim.epw_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Jeez I'm saying that a lot in this notebook.\n",
    "\n",
    "Let's run an actual simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# capture hides output\n",
    "res_hourly, res_monthly = whitebox_sim.simulate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it simulated successfully! Let's confirm by taking a look at the the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_hourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(res_hourly[\"System\"][\"BLOCK CORE STOREY 0 IDEAL LOADS AIR SYSTEM\"]*2.777e-7, linewidth=0.3)\n",
    "txt = plt.title(\"Hourly/Core\")\n",
    "fig = plt.figure()\n",
    "plt.plot(res_hourly[\"System\"][\"BLOCK PERIM STOREY 0 IDEAL LOADS AIR SYSTEM\"]*2.777e-7, linewidth=0.3)\n",
    "txt = plt.title(\"Hourly/Perim\")\n",
    "fig = plt.figure()\n",
    "plt.plot(res_monthly[\"System\"][\"BLOCK CORE STOREY 0 IDEAL LOADS AIR SYSTEM\"]*2.777e-7, linewidth=0.3)\n",
    "txt = plt.title(\"Monthly/Core\")\n",
    "fig = plt.figure()\n",
    "plt.plot(res_monthly[\"System\"][\"BLOCK PERIM STOREY 0 IDEAL LOADS AIR SYSTEM\"]*2.777e-7, linewidth=0.3)\n",
    "txt = plt.title(\"Monthly/Perim\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Simulation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at simulating a whole batch.\n",
    "\n",
    "First, we need to instantiate the batch simulator.  This configures an object which will automatically handle identifying and opening the correct storage vector batch, and can automatically run simulations in parallel and write results to a new HDF5 file.  It will also automatically upload the results files to the cloud bucket.\n",
    "\n",
    "*nb: `simulate.py` can be called from the CLI in order to facilitate easily launching many Batches simultaneously from many processes running on multiple servers, i.e.* `python simulate.py <batch_id> <n of processes>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate import BatchSimulator\n",
    "batch_runner = BatchSimulator(schema, batch_id=23, processes=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate, all we need to do is call the `run` method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "batch_runner.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we can automatically upload the results to the Google storage bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_runner.upload()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = None\n",
    "with h5py.File(\"./data/hdf5/batch_00023_results.hdf5\", 'r') as f:\n",
    "    results = f[\"hourly\"][...] # this loads the whole batch into memory!\n",
    "\n",
    "print(results.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(results[0,0,:]*2.777e-7, linewidth=0.5)\n",
    "plt.plot(results[0,1,:]*2.777e-7, linewidth=0.5)\n",
    "fig = plt.figure()\n",
    "plt.plot(results[0,2,:]*2.777e-7, linewidth=0.5)\n",
    "plt.plot(results[0,3,:]*2.777e-7, linewidth=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-for-bem-sampling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
