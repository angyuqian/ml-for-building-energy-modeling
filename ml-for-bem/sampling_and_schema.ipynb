{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema Usage\n",
    "\n",
    "The schema does not actually store any data.  Instead, it is an interface which allows us to interact with numpy/torch tensors in a semantic manner.  It lets us convert between storage vectors (i.e. how we store the building parameters numerically on disk), simulation objects (e.g. Archetypal Templates and PyUmi Shoeboxes) and machine learning model imports (i.e. torch tensors with full hourly schedule data)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup\n",
    "\n",
    "We need some jank to get relative imports working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schema import Schema, ShoeboxGeometryParameter, BuildingTemplateParameter, WhiteboxSimulation\n",
    "schema = Schema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what's in the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batch_id',\n",
       " 'variation_id',\n",
       " 'base_template_lib',\n",
       " 'base_template',\n",
       " 'base_epw',\n",
       " 'width',\n",
       " 'height',\n",
       " 'facade_2_footprint',\n",
       " 'perim_2_footprint',\n",
       " 'roof_2_footprint',\n",
       " 'footprint_2_ground',\n",
       " 'shading_fact',\n",
       " 'wwr_n',\n",
       " 'wwr_e',\n",
       " 'wwr_s',\n",
       " 'wwr_w',\n",
       " 'orientation',\n",
       " 'LightingPowerDensity',\n",
       " 'EquipmentPowerDensity',\n",
       " 'PeopleDensity',\n",
       " 'FacadeRValue',\n",
       " 'RoofRValue',\n",
       " 'PartitionRValue',\n",
       " 'SlabRValue',\n",
       " 'schedules_seed',\n",
       " 'schedules']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema.parameter_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access a schema parameter from the schema with list indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---width---\n",
      "shape_storage=(1,), shape_ml=(1,), dtype=scalar\n",
      "Width [m]\n",
      "---schedules---\n",
      "shape_storage=(8, 16), shape_ml=(8, 8760), dtype=matrix\n",
      "A matrix in the storage vector with operations to apply to schedules; a matrix of timeseries in ml vector\n",
      "---orientation---\n",
      "shape_storage=(1,), shape_ml=(4,), dtype=onehot\n",
      "Shoebox Orientation\n"
     ]
    }
   ],
   "source": [
    "print(schema[\"width\"])\n",
    "print(schema[\"schedules\"])\n",
    "print(schema[\"orientation\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that each parameter may have multiple different lengths in the storage vector and ML vector.\n",
    "\n",
    "We can also print a summary of the whole schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Schema --------\n",
      "---- batch_id ----\n",
      "shape storage: (1,) / shape ml: (0,)\n",
      "location storage: 0->1 / location ml: 0->0\n",
      "\n",
      "---- variation_id ----\n",
      "shape storage: (1,) / shape ml: (0,)\n",
      "location storage: 1->2 / location ml: 0->0\n",
      "\n",
      "---- base_template_lib ----\n",
      "shape storage: (1,) / shape ml: (0,)\n",
      "location storage: 2->3 / location ml: 0->0\n",
      "\n",
      "---- base_template ----\n",
      "shape storage: (1,) / shape ml: (0,)\n",
      "location storage: 3->4 / location ml: 0->0\n",
      "\n",
      "---- base_epw ----\n",
      "shape storage: (1,) / shape ml: (0,)\n",
      "location storage: 4->5 / location ml: 0->0\n",
      "\n",
      "---- width ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 5->6 / location ml: 0->1\n",
      "\n",
      "---- height ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 6->7 / location ml: 1->2\n",
      "\n",
      "---- facade_2_footprint ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 7->8 / location ml: 2->3\n",
      "\n",
      "---- perim_2_footprint ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 8->9 / location ml: 3->4\n",
      "\n",
      "---- roof_2_footprint ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 9->10 / location ml: 4->5\n",
      "\n",
      "---- footprint_2_ground ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 10->11 / location ml: 5->6\n",
      "\n",
      "---- shading_fact ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 11->12 / location ml: 6->7\n",
      "\n",
      "---- wwr_n ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 12->13 / location ml: 7->8\n",
      "\n",
      "---- wwr_e ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 13->14 / location ml: 8->9\n",
      "\n",
      "---- wwr_s ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 14->15 / location ml: 9->10\n",
      "\n",
      "---- wwr_w ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 15->16 / location ml: 10->11\n",
      "\n",
      "---- orientation ----\n",
      "shape storage: (1,) / shape ml: (4,)\n",
      "location storage: 16->17 / location ml: 11->15\n",
      "\n",
      "---- LightingPowerDensity ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 17->18 / location ml: 15->16\n",
      "\n",
      "---- EquipmentPowerDensity ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 18->19 / location ml: 16->17\n",
      "\n",
      "---- PeopleDensity ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 19->20 / location ml: 17->18\n",
      "\n",
      "---- FacadeRValue ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 20->21 / location ml: 18->19\n",
      "\n",
      "---- RoofRValue ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 21->22 / location ml: 19->20\n",
      "\n",
      "---- PartitionRValue ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 22->23 / location ml: 20->21\n",
      "\n",
      "---- SlabRValue ----\n",
      "shape storage: (1,) / shape ml: (1,)\n",
      "location storage: 23->24 / location ml: 21->22\n",
      "\n",
      "---- schedules_seed ----\n",
      "shape storage: (1,) / shape ml: (0,)\n",
      "location storage: 24->25 / location ml: 22->22\n",
      "\n",
      "---- schedules ----\n",
      "shape storage: (8, 16) / shape ml: (8, 8760)\n",
      "location storage: 25->153 / location ml: 22->70102\n",
      "\n",
      "Total length of storage vectors: 153 / Total length of ml vectors: 70102\n"
     ]
    }
   ],
   "source": [
    "print(schema)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the length of the storage vector is significantly smaller than the length the vector the ML model will see."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating new design vectors in storage space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's generate a new, empty design vector, and update the Roof R-Value, and then check that it updated correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_vector = schema.generate_empty_storage_vector()\n",
    "schema.update_storage_vector(storage_vector=storage_vector, parameter=\"RoofRValue\", value=25)\n",
    "schema[\"RoofRValue\"].extract_storage_values(storage_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print out the full vector, we should be able to see th 25 and a whole bunch of zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0. 25.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(storage_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new batch of designs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 153)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 20\n",
    "storage_batch = schema.generate_empty_storage_batch(batch_size)\n",
    "storage_batch.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we see that it has 20 design vectors with 151 values each.\n",
    "\n",
    "Let's try updating all of the facade R-values values in a batch with the same value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.],\n",
       "       [14.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema.update_storage_batch(storage_batch, parameter=\"FacadeRValue\", value=14)\n",
    "schema[\"FacadeRValue\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try updating an entire batch with random values.  We can also unnormalize the uniform random variable into the desired range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48.02043847],\n",
       "       [44.80044669],\n",
       "       [24.64897817],\n",
       "       [28.89868358],\n",
       "       [17.59036769],\n",
       "       [17.039554  ],\n",
       "       [14.34904611],\n",
       "       [ 8.92106945],\n",
       "       [19.86139997],\n",
       "       [30.41673716],\n",
       "       [43.25102013],\n",
       "       [22.33180313],\n",
       "       [ 0.94045779],\n",
       "       [46.57060752],\n",
       "       [ 4.49791131],\n",
       "       [45.33549661],\n",
       "       [32.94428606],\n",
       "       [30.45486421],\n",
       "       [11.27376663],\n",
       "       [25.25373025]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter = \"SlabRValue\"\n",
    "n = batch_size\n",
    "shape = (n, *schema[parameter].shape_storage)\n",
    "values = np.random.rand(*shape) # create a random sample with appropriate shape\n",
    "values = schema[parameter].unnormalize(values) # schema parameter must be a numeric type with min/max defined for unnormalize to work\n",
    "schema.update_storage_batch(storage_batch, parameter=parameter, value=values)\n",
    "schema[parameter].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try updating just a subset of the batch by using the `index` parameter:\n",
    "\n",
    "*nb: we can also use an int instead of a tuple for `index` to only update a single vector's parameter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.        ],\n",
       "       [0.80454181],\n",
       "       [0.74450642],\n",
       "       [0.18897392],\n",
       "       [0.92171292],\n",
       "       [0.19958642],\n",
       "       [0.98532759],\n",
       "       [0.55733225],\n",
       "       [0.92528026],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 2\n",
    "n = 8\n",
    "end = start + n\n",
    "parameter = \"PartitionRValue\"\n",
    "shape = (n, *schema[parameter].shape_storage)\n",
    "values = np.random.rand(*shape) # create a random sample with appropriate shape\n",
    "\n",
    "schema.update_storage_batch(storage_batch, index=(start,end), parameter=parameter, value=values)\n",
    "schema[parameter].extract_storage_values_batch(storage_batch) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful technique will be to start with a small batch, and then duplicate it in concatenations along `axis=0` as we build up our mixed grid/hypercube/random samples.  Let's start by creating a new batch with a single vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 153)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_batch = schema.generate_empty_storage_batch(1)\n",
    "storage_batch.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say some baseline parameters (e.g. pulled from ResStock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  0. ,  2. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  7.2,  0. ,  0. , 20. , 30. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  2. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  7.2,  0. ,  0. , 20. , 30. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  2. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  7.2,  0. ,  0. , 20. , 30. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  2. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  7.2,  0. ,  0. , 20. , 30. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
       "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema.update_storage_batch(storage_batch, parameter=\"FacadeRValue\", value=20)\n",
    "schema.update_storage_batch(storage_batch, parameter=\"RoofRValue\", value=30)\n",
    "schema.update_storage_batch(storage_batch, parameter=\"LightingPowerDensity\", value=7.2)\n",
    "schema.update_storage_batch(storage_batch, parameter=\"base_template_lib\", value=0)\n",
    "schema.update_storage_batch(storage_batch, parameter=\"base_template\", value=2)\n",
    "storage_batch = np.concatenate([storage_batch for _ in range(4)], axis=0)\n",
    "storage_batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set the orientations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = np.arange(4).reshape(-1,1)\n",
    "parameter = \"orientation\"\n",
    "schema.update_storage_batch(storage_batch, parameter=parameter, value=values)\n",
    "schema[parameter].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!  Now let's stack this up and begin generating some geometric variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientations_per_base = 4\n",
    "geometric_variations_per_orientation = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 153)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_batch = np.repeat(storage_batch, geometric_variations_per_orientation, axis=0)\n",
    "storage_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema[\"orientation\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!  let's start populating this: if we wanted to use repeating values, we could do nested loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = geometric_variations_per_orientation # how many design vectors in this mini batch\n",
    "for i in range(orientations_per_base):\n",
    "\tstart = i*n # where this mini batch starts in the parent batch\n",
    "\tend = start + n # where this mini batch ends in the parent batch\n",
    "\tfor j,parameter in enumerate(schema.parameters):\n",
    "\t\tif isinstance(parameter, ShoeboxGeometryParameter):\n",
    "\t\t\tname = parameter.name\n",
    "\t\t\tshape = parameter.shape_storage\n",
    "\t\t\tnp.random.seed(j+20923) # arbitrary but reliable seed\n",
    "\t\t\tvalues = np.random.rand(n, *shape) \n",
    "\t\t\tvalues = parameter.unnormalize(values)\n",
    "\t\t\tschema.update_storage_batch(storage_batch, index=(start,end), parameter=name, value=values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40193869],\n",
       "       [0.5068512 ],\n",
       "       [0.05550449],\n",
       "       [0.61793909],\n",
       "       [0.97010965],\n",
       "       [0.40193869],\n",
       "       [0.5068512 ],\n",
       "       [0.05550449],\n",
       "       [0.61793909],\n",
       "       [0.97010965],\n",
       "       [0.40193869],\n",
       "       [0.5068512 ],\n",
       "       [0.05550449],\n",
       "       [0.61793909],\n",
       "       [0.97010965],\n",
       "       [0.40193869],\n",
       "       [0.5068512 ],\n",
       "       [0.05550449],\n",
       "       [0.61793909],\n",
       "       [0.97010965]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema[\"wwr_e\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.78130396],\n",
       "       [3.51381631],\n",
       "       [3.3350721 ],\n",
       "       [3.49815937],\n",
       "       [3.63602159],\n",
       "       [2.78130396],\n",
       "       [3.51381631],\n",
       "       [3.3350721 ],\n",
       "       [3.49815937],\n",
       "       [3.63602159],\n",
       "       [2.78130396],\n",
       "       [3.51381631],\n",
       "       [3.3350721 ],\n",
       "       [3.49815937],\n",
       "       [3.63602159],\n",
       "       [2.78130396],\n",
       "       [3.51381631],\n",
       "       [3.3350721 ],\n",
       "       [3.49815937],\n",
       "       [3.63602159]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema[\"width\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, these are repeating correctly!  Now, suppose we want to just slightly perturb all of these so that they aren't perfectly repeating, but are close to repeating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.80420975],\n",
       "       [3.49944713],\n",
       "       [3.31434004],\n",
       "       [3.48208096],\n",
       "       [3.73598473],\n",
       "       [2.84118628],\n",
       "       [3.47441335],\n",
       "       [3.40808489],\n",
       "       [3.5183108 ],\n",
       "       [3.62643995],\n",
       "       [2.76048953],\n",
       "       [3.52577953],\n",
       "       [3.42346187],\n",
       "       [3.50232399],\n",
       "       [3.65261209],\n",
       "       [2.80347539],\n",
       "       [3.47244618],\n",
       "       [3.42633211],\n",
       "       [3.53406335],\n",
       "       [3.6056001 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = storage_batch.shape[0]\n",
    "for i,parameter in enumerate(schema.parameters):\n",
    "\tif isinstance(parameter, ShoeboxGeometryParameter):\n",
    "\t\tname = parameter.name\n",
    "\t\tshape = parameter.shape_storage\n",
    "\t\tperturbations = np.random.rand(n,*shape)*0.2 - 0.1\n",
    "\t\tvalues = parameter.extract_storage_values_batch(storage_batch)\n",
    "\t\tvalues += perturbations\n",
    "\t\tschema.update_storage_batch(storage_batch,parameter=name,value=values)\n",
    "\n",
    "schema[\"width\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  We see that they are close to their previous values, but not identical.  \n",
    "\n",
    "Alternatively, we might prefer to simply use fully random geometric variations for all of our orientation duplicates, rather than repeating the geometry across orientations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.54192598],\n",
       "       [3.28019477],\n",
       "       [2.06272822],\n",
       "       [4.80451971],\n",
       "       [2.96040011],\n",
       "       [3.74392342],\n",
       "       [3.56022333],\n",
       "       [2.63973389],\n",
       "       [3.91255668],\n",
       "       [3.25271467],\n",
       "       [2.10632626],\n",
       "       [2.99321069],\n",
       "       [1.90537471],\n",
       "       [4.94921847],\n",
       "       [2.15048627],\n",
       "       [2.63889603],\n",
       "       [3.02341448],\n",
       "       [2.26501573],\n",
       "       [1.56856173],\n",
       "       [4.95948345]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = storage_batch.shape[0]\n",
    "for i,parameter in enumerate(schema.parameters):\n",
    "\tif isinstance(parameter, ShoeboxGeometryParameter):\n",
    "\t\tname = parameter.name\n",
    "\t\tshape = parameter.shape_storage\n",
    "\t\tvalues = np.random.rand(n,*shape)\n",
    "\t\tvalues = parameter.unnormalize(values)\n",
    "\t\tschema.update_storage_batch(storage_batch,parameter=name,value=values)\n",
    "\n",
    "schema[\"width\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on in this file, we will be inspecting template parameters as well, so let's just arbitrarily set some building template parameters for each design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.11827834],\n",
       "       [ 0.64411733],\n",
       "       [ 9.97302006],\n",
       "       [ 0.68677802],\n",
       "       [ 5.82475166],\n",
       "       [ 2.77722966],\n",
       "       [ 4.73947018],\n",
       "       [ 3.44416997],\n",
       "       [17.98872002],\n",
       "       [17.20925426],\n",
       "       [18.70569818],\n",
       "       [15.35699898],\n",
       "       [18.13810333],\n",
       "       [12.03525967],\n",
       "       [ 8.38111888],\n",
       "       [ 1.44164747],\n",
       "       [17.18791715],\n",
       "       [18.40693733],\n",
       "       [14.54873116],\n",
       "       [ 1.4413146 ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = storage_batch.shape[0]\n",
    "for i,parameter in enumerate(schema.parameters):\n",
    "\tif isinstance(parameter, BuildingTemplateParameter):\n",
    "\t\tname = parameter.name\n",
    "\t\tshape = parameter.shape_storage\n",
    "\t\tvalues = np.random.rand(n,*shape)\n",
    "\t\tvalues = parameter.unnormalize(values)\n",
    "\t\tschema.update_storage_batch(storage_batch,parameter=name,value=values)\n",
    "\n",
    "schema[\"LightingPowerDensity\"].extract_storage_values_batch(storage_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose this was our finished batch.  We can save it to an HDF5 file.  Let's say this was building 23 from our ResStock database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from storage import upload_to_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the building IDs\n",
    "batch_id = 23 # suppose this is the base building we are drawing from\n",
    "n = storage_batch.shape[0]\n",
    "variation_ids = np.arange(n)\n",
    "schema.update_storage_batch(storage_batch,parameter=\"batch_id\",value=batch_id)\n",
    "schema.update_storage_batch(storage_batch,parameter=\"variation_id\",value=variation_ids)\n",
    "\n",
    "# Write to an HDF5 file\n",
    "slug = f\"batch_{batch_id:04d}.hdf5\"\n",
    "outfile = f\"./data/{slug}\"\n",
    "with h5py.File(outfile,\"w\") as f:\n",
    "    f.create_dataset(name=\"storage_vectors\", shape=storage_batch.shape, dtype=storage_batch.dtype, data=storage_batch)\n",
    "\n",
    "# upload to cloud bucket for easy backup\n",
    "destination = f\"demo-batch-data/{slug}\"\n",
    "upload_to_bucket(destination, outfile)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's suppose you want to simulate a design vector.  Let's open up an HDF5 file and read in only the first storage vector to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.0, 0.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_id = 23\n",
    "slug = f\"batch_{batch_id:04d}.hdf5\"\n",
    "outfile = f\"./data/{slug}\"\n",
    "storage_vector = None\n",
    "with h5py.File(outfile,'r') as f:\n",
    "    storage_vector = f[\"storage_vectors\"][0]\n",
    "\n",
    "schema[\"batch_id\"].extract_storage_values(storage_vector), schema[\"variation_id\"].extract_storage_values(storage_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Looks like we successfully opened the 0th design variation from batch 23.\n",
    "\n",
    "Now let's create a simulation object for this storage vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitebox_sim = WhiteboxSimulation(schema, storage_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at the semantic objects that have been configured!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.902105808817122\n",
      "4.541925983297659\n",
      "16.118278340507985\n",
      "16.118278340507985\n",
      "0.5171993567612133\n"
     ]
    }
   ],
   "source": [
    "print(whitebox_sim.shoebox_config.facade_2_footprint)\n",
    "print(whitebox_sim.shoebox_config.width)\n",
    "print(whitebox_sim.template.Perimeter.Loads.LightingPowerDensity)\n",
    "print(whitebox_sim.template.Core.Loads.PeopleDensity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-for-bem-sampling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
